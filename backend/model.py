# -*- coding: utf-8 -*-
"""Untitled28.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pwyRH0PG7N5DjbesbzTyxghikXTln7Dr

Importing all libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report
import xgboost as xgb
import lightgbm as lgb
import pickle
import warnings
warnings.filterwarnings('ignore')

"""EDA AND DATA CLEANING"""

df = pd.read_csv('telco_churn.csv')
print(df.head())
print(f"\nShape: {df.shape}")
print(f"\nData Types:\n{df.dtypes}")
print(f"\nMissing Values:\n{df.isnull().sum()}")

df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
df = df.dropna()
print(f"\nShape after cleaning: {df.shape}")

df = df.drop('customerID', axis=1)

"""MAPPING AND DISTRIBUTION ANALYSIS"""

df['Churn'] = df['Churn'].map({'No': 0, 'Yes': 1})
print(f"\nChurn Distribution:")
print(df['Churn'].value_counts())

plt.figure(figsize=(10, 4))
sns.countplot(x='Churn', data=df, palette='Set2')
plt.title('Churn Distribution')
plt.ylabel('Count')
plt.show()

"""ENCOING CATEGORICAL COLUMNS & DIVIDING DATA"""

le = LabelEncoder()
for col in df.select_dtypes(include=['object']).columns:
    df[col] = le.fit_transform(df[col])

print(f"\nEncoded Data:")
print(df.head())

X = df.drop('Churn', axis=1)
y = df['Churn']

"""**CHECKING CORRELATIONS & REMOVING UNWANTED FEATURES**"""

numeric_cols = X.select_dtypes(include=[np.number]).columns
correlation_matrix = X[numeric_cols].corr()

plt.figure(figsize=(14, 10))
sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0)
plt.title('Feature Correlation Matrix')
plt.tight_layout()
plt.show()

churn_correlation = pd.concat([X[numeric_cols], y], axis=1).corr()['Churn'].sort_values(ascending=False)
print(f"\nFeature Correlation with Churn:")
print(churn_correlation)

plt.figure(figsize=(10, 6))
churn_correlation.drop('Churn').plot(kind='barh', color='steelblue')
plt.title('Feature Correlation with Churn Target')
plt.xlabel('Correlation Coefficient')
plt.tight_layout()
plt.show()

threshold = 0.01
relevant_features = churn_correlation[abs(churn_correlation) > threshold].index.tolist()
if 'Churn' in relevant_features:
    relevant_features.remove('Churn')
X = X[relevant_features]

print(f"\nFeatures after correlation filtering: {X.shape[1]}")
print(f"Removed {df.shape[1] - 1 - X.shape[1]} irrelevant features")

"""SCALING AND SPLITTING DATA FOR TRAINING"""

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)

print(f"\nX shape: {X_scaled.shape}")
print(f"y shape: {y.shape}")

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Train: {X_train.shape}, Test: {X_test.shape}")

models = [
    ('Logistic Regression', LogisticRegression(max_iter=1000, random_state=42)),
    ('Random Forest', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)),
    ('Gradient Boosting', GradientBoostingClassifier(n_estimators=100, random_state=42)),
    ('XGBoost', xgb.XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0)),
    ('LightGBM', lgb.LGBMClassifier(n_estimators=100, random_state=42, n_jobs=-1, verbose=-1))
]

cv_results = []

for model_name, model in models:
    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc', n_jobs=-1)
    mean_score = cv_scores.mean()
    std_score = cv_scores.std()

    cv_results.append({
        'Model': model_name,
        'Mean CV Score': mean_score,
        'Std Dev': std_score,
        'Model Object': model
    })

    print(f"\n{model_name}:")
    print(f"  CV Scores: {[f'{score:.4f}' for score in cv_scores]}")
    print(f"  Mean: {mean_score:.4f} | Std: {std_score:.4f}")

cv_df = pd.DataFrame({
    'Model': [r['Model'] for r in cv_results],
    'Mean CV Score': [r['Mean CV Score'] for r in cv_results],
    'Std Dev': [r['Std Dev'] for r in cv_results]
})

plt.figure(figsize=(10, 6))
sns.barplot(data=cv_df, x='Mean CV Score', y='Model', palette='viridis')
plt.title('Cross-Validation AUC-ROC Scores')
plt.xlabel('Mean AUC-ROC Score')
plt.tight_layout()
plt.show()

"""IDENTIFYING THE BEST MODEL AND TRAINING"""

best_result = max(cv_results, key=lambda x: x['Mean CV Score'])
best_model_name = best_result['Model']
best_model = best_result['Model Object']
best_cv_score = best_result['Mean CV Score']

print(f"\n BEST MODEL: {best_model_name}")
print(f"CV Score: {best_cv_score:.4f}\n")

best_model.fit(X_train, y_train)

y_pred = best_model.predict(X_test)
y_pred_proba = best_model.predict_proba(X_test)[:, 1]

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
auc = roc_auc_score(y_test, y_pred_proba)

print(f"TEST SET METRICS")
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
print(f"AUC-ROC: {auc:.4f}")

cm = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:")
print(cm)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])
plt.title(f'Confusion Matrix - {best_model_name}')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.tight_layout()
plt.show()

print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=['No Churn', 'Churn']))

"""DUMPING THE MODEL"""

with open('best_model.pkl', 'wb') as f:
    pickle.dump(best_model, f)

with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)